

/*:
 # Info
 ## The neural network and its precision

To allow the Playground to recognize the hand, I created my personal neural network with my iPhone camera, hundreds photos of my hands and a third part free online tool. The precision of this neural network is about 90% to recognise the right gesture that you are reproducing: obviously it is influenced by light condition and ceiling color but it works enough well.
 To use the neural network in this playground, I created another project in Xcode that I used to compile the neural network model and then I putted it in to the playground.
*/

/*:
 # About me
 
 I’m Vincenzo Aceto. I’m 28 years old and I came from Cosenza (Italy). I’m half-canadian: my father was born in Toronto. I’m a student of Apple Developer Academy at Università Federico II. Before this experience I was a mobile developer for an IT Company and I developed many apps for important customers in Android and Xamarin.
 
 To see all the code of this playground, the modelML of my neural network and all the staffs related to this project, see [my GitHub repository.](https://github.com/vinzaceto/WWDCPlayground.git)
 
 It was my first time using machine learning and I was being really fascinated about this world.
 */

/*:
 # Help
 ## List of the gestures used in the neural network

![Hand closed](hand_0.png)
![Hand with one finger](hand_1.png)
![Hand with two fingers, like a gun](hand_2.png)
![Hand with three fingers](hand_3.png)
![Hand with four fingers](hand_4.png)
![Hand with five fingers](hand_5.png)
*/
